# ğŸ“ QA Tutor Chatbot

Ein intelligenter Lernbegleiter-Chatbot mit integriertem Faktenwissen, WirLernenOnline.de-Integration und Learning Analytics.

## âœ¨ Features

### ğŸ§  Hybrides Antwortsystem
- **QA-Dataset**: Vordefinierte Frage-Antwort-Paare mit semantischer Suche
- **KI-Integration**: OpenAI GPT-4o-mini und GWDG LLM Support
- **Intelligente Priorisierung**: QA-Paare haben Vorrang vor KI-generierten Antworten

### ğŸ“š WirLernenOnline.de Integration
- Automatische Extraktion von Lernmetadaten aus Nutzerfragen
- Suche nach passenden Lernmaterialien Ã¼ber WLO API
- Integration der Materialien in KI-Antworten mit direkten Links
- Filterung nach FÃ¤chern, Inhaltstypen und Quellen

### ğŸ“Š Learning Analytics
- Asynchrone Lernziel-Analyse basierend auf Bloom'scher Taxonomie
- Echtzeit-Fortschritts-Tracking pro Thema
- Lernerprofil-Erfassung (Bildungsstufe, PrÃ¤ferenzen, Motivation)
- Zeiterfassung pro Lernsession
- Visualisierung in der linken Seitenleiste

### âš™ï¸ Konfigurierbare Einstellungen
- **LLM Provider**: OpenAI oder GWDG
- **QA-Dataset**: Ein-/Ausschaltbar mit konfigurierbarer Ã„hnlichkeitsschwelle
- **WLO Integration**: Optional mit Debug-Modus und Quellenfilter
- **Learning Analytics**: Automatische Analyse nach jeder Antwort

## ğŸš€ Installation

### Voraussetzungen
- Node.js (Version 18+)
- npm oder yarn

### Setup

1. **Repository klonen**
   ```bash
   git clone <repository-url>
   cd QA-Chatbot
   ```

2. **Dependencies installieren**
   ```bash
   npm install
   ```

3. **Umgebungsvariablen konfigurieren**
   
   Erstelle eine `.env` Datei im Hauptverzeichnis:
   ```env
   # OpenAI Configuration
   VITE_OPENAI_API_KEY=your_openai_api_key_here
   
   # GWDG Configuration (optional)
   VITE_GWDG_API_KEY=your_gwdg_api_key_here
   ```

4. **Development Server starten**
   ```bash
   npm run dev
   ```

   Die Anwendung ist dann unter `http://localhost:5173` verfÃ¼gbar.

## ğŸ—ï¸ Projektstruktur

```
QA-Chatbot/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ quant/                      # Kompakte Embedding-Assets (+ items.json)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ precompute_openai_embeddings.py  # Python: Embeddings + PCA/Int8 export
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ WLOSidebar.jsx
â”‚   â”‚   â””â”€â”€ LearningAnalyticsSidebar.jsx
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ chatUtils.js
â”‚   â”‚   â”œâ”€â”€ systemPrompt.js         # Zentraler System-Prompt
â”‚   â”‚   â”œâ”€â”€ datasetLoader.js        # LÃ¤dt nur /quant/*.items.json und *.meta.json
â”‚   â”‚   â”œâ”€â”€ learningAnalytics.js
â”‚   â”‚   â”œâ”€â”€ mappings.js
â”‚   â”‚   â””â”€â”€ types.js
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ openaiService.js        # LLM-Calls, QA-Matching (nur Embeddings)
â”‚   â”‚   â””â”€â”€ embeddingService.js     # PCA/Int8 Projektion & Suche
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ main.jsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.js                  # Vite Konfiguration mit Proxies
â””â”€â”€ .env                           # Umgebungsvariablen
```

## ğŸ”§ Konfiguration

### LLM Provider

**OpenAI (Standard)**
- Modell: gpt-4o-mini
- BenÃ¶tigt: `VITE_OPENAI_API_KEY`

**GWDG**
- Modell (Default): gpt-oss-120b (konfigurierbar via `VITE_GWDG_API_MODEL`)
- BenÃ¶tigt: `VITE_GWDG_API_KEY`
- Endpoint: wird Ã¼ber Vite-Proxy `/api/gwdg/v1` konfiguriert (siehe `vite.config.js`)

### QA-Dataset

- StandardmÃ¤ÃŸig lÃ¤dt die App kompakte DatensÃ¤tze aus `public/quant/<datasetId>.items.json` und `public/quant/<datasetId>.meta.json`.
- Es gibt keinen Fallback auf `src/data/`; nur Quant-Assets werden unterstÃ¼tzt.
- Standard-Dataset: `qa_Klexikon-Prod-180825` (konfigurierbar im Interface).
- Auswahl des Datensatzes erfolgt im Interface (Einstellungen â†’ Dataset-Auswahl).

**Ausgangsdaten (Quelle) â€“ JSON Schema:**

```json
[
  {
    "question": "Was ist HTML?",
    "answer": "HTML steht fÃ¼r HyperText Markup Language...",
    "url": "https://example.com/primer",
    "category": "Web Development",
    "type": "definition",
    "difficulty": "beginner",
    "node_id": 12345,
    "level": "Sek I"
  }
]
```

Hinweise:
- Pflichtfelder: `question`, `answer`
- Optionale Felder: `url` (alias `wwwurl`), `category` (alias `subject`), `type`, `difficulty`, `node_id` (alias `id`), `level`

### WLO Integration

Die WLO-Integration nutzt die edu-sharing API von WirLernenOnline.de:
- Automatische Metadaten-Extraktion aus Nutzerfragen
- Mapping von Themen zu WLO-FÃ¤chern und Inhaltstypen
- Integration der gefundenen Materialien in KI-Antworten

## ğŸ¯ Verwendung

### Chat-Interface
1. Stelle eine Frage im Chat-Eingabefeld
2. Der Bot prÃ¼ft zuerst das QA-Dataset auf passende Antworten
3. Falls keine QA-Antwort gefunden wird, wird die WLO-Integration aktiviert
4. Passende Lernmaterialien werden in der rechten Seitenleiste angezeigt
5. Learning Analytics werden automatisch in der linken Seitenleiste aktualisiert

### Einstellungen
Klicke auf das Zahnrad in der Statusleiste, um:
- LLM Provider zu wechseln (OpenAI/GWDG)
- QA-Paare zu aktivieren/deaktivieren
- Dataset auszuwÃ¤hlen (wenn mehrere vorhanden sind)
- Ã„hnlichkeitsschwelle (Cosine-Score) festzulegen
- WLO-Integration zu konfigurieren (Debug/Quellenfilter)

Antwort-Labels im Chat:
- **[GEPRÃœFTE ANTWORT AUF QA-BASIS]** bei QA-Treffern (mit Quelle/Link)
- **[UNSICHERE ANTWORT AUF KI-BASIS]** wenn kein QA-Treffer; ggf. ergÃ¤nzende ErklÃ¤rung nach QA-Teil

### Learning Analytics
Die linke Seitenleiste zeigt:
- Aktuelle Lernziele basierend auf Bloom'scher Taxonomie
- Fortschritt pro Themenbereich
- Zeiterfassung der aktuellen Session
- Lernerprofil-Informationen

## ğŸ› ï¸ Development

### Build fÃ¼r Produktion
```bash
npm run build
```

### Linting
```bash
npm run lint
```

### Preview der Production Build
```bash
npm run preview
```

## ğŸ”Œ API Integrationen

### OpenAI API
- Endpoint: https://api.openai.com/v1
- Modell: gpt-4.1-mini
- Verwendung: HauptsÃ¤chliche KI-Antworten und Learning Analytics

### GWDG API
- Endpoint: https://chat-ai.academiccloud.de/v1
- Modell: gpt-oss-120b
- Verwendung: Alternative zu OpenAI API

### WirLernenOnline.de API
- Endpoint: https://www.wirlernenonline.de/api/v1
- Verwendung: Suche nach Lernmaterialien
- Proxy konfiguriert in `vite.config.js`

## ğŸ“ Anpassungen

### Neue QA-Paare hinzufÃ¼gen
So bringst du neue/aktualisierte QA-Daten in die App:

- Quelle: Bearbeite eine JSON-Datei mit QA-Paaren (z. B. `scripts/qa_*.json`).
- Preprocessing: Erzeuge kompakte Assets mit dem Python-Skript (siehe unten) und Ausgabe nach `public/quant/`.
- Ergebnis: Mindestens `<datasetId>.items.json` und `<datasetId>.meta.json` (plus Embedding-BinÃ¤rdateien, falls konfiguriert).
- Nutzung: App neu laden; Dataset im Interface auswÃ¤hlen.

### WLO-Mappings erweitern
Bearbeite `src/lib/mappings.js` um neue FÃ¤cher oder Inhaltstypen hinzuzufÃ¼gen.

### Learning Analytics anpassen
Modifiziere `src/lib/learningAnalytics.js` fÃ¼r neue Analyse-Kriterien.

## âš¡ Kompakte Embeddings (PCA + Int8)

Zur effizienten Auslieferung groÃŸer QA-DatensÃ¤tze unterstÃ¼tzt die App kompakte Embeddings mit PCA-Reduktion und Int8-Quantisierung. Diese werden offline per Python-Skript erzeugt und zur Laufzeit automatisch genutzt.

### Datenablage
- **Eingabe (Q/A-Inhalte):** JSON-Datei mit QA-Paaren an einem beliebigen Ort (z. B. unter `scripts/`).
- **Ausgabe (kompakte Embeddings + Items):** Dateien unter `public/quant/`, Laufzeitpfad `/quant/*`.
- `datasetId` = Dateiname ohne `.json` und PrÃ¤fix fÃ¼r alle Ausgabedateien.

### Vorbereitung per Python (empfohlen)
Voraussetzungen: `pip install --upgrade openai numpy`

PowerShell (Windows):
```powershell
$env:OPENAI_API_KEY = "<dein-openai-key>"
python scripts/precompute_openai_embeddings.py -i scripts/qa_Klexikon-Prod-180825.json --out-dir public/quant --pca-dim 256 --quantize -c 20
```

Hinweise:
- Der Befehl erzeugt folgende Dateien in `public/quant/`:
  - `qa_Klexikon-Prod-180825.embeddings.bin`
  - `qa_Klexikon-Prod-180825.pca_components.bin`
  - `qa_Klexikon-Prod-180825.pca_mean.bin`
  - `qa_Klexikon-Prod-180825.meta.json`
  - `qa_Klexikon-Prod-180825.items.json`
- Die App nutzt ausschlieÃŸlich diese kompakten Assets zur Laufzeit.
- Die JSON mit QA-Paaren dient nur als Quelle fÃ¼r die Vorverarbeitung; sie wird nicht mehr direkt geladen.

Optional statt Kopie neben das Skript: Du kannst bei `-i` auch einen relativen Pfad zur JSON-Datei angeben (z. B. `scripts/â€¦`), wenn du das bevorzugst.

### Laufzeitverhalten
- Die App lÃ¤dt automatisch `/quant/<datasetId>.items.json` und `/quant/<datasetId>.meta.json` und sucht nur per Embeddings.
- Es gibt keinen Fallback auf JSON-Dateien im Quellcode.
- Empfohlene Einstellungen: PCA-Dimension `256`, Quantisierung `Int8`.

### Troubleshooting
- Nach dem Kopieren/Erzeugen der BinÃ¤rdateien einmal hart neu laden (Browser-Cache), da Assets mit `cache: 'force-cache'` geladen werden.
- Achte auf identische `datasetId` zwischen deiner Quelle und den Dateien in `public/quant/<id>.*`.
- Bei Ã„nderungen an Reihenfolge/Anzahl der Q/A-Items in der JSON die kompakten Assets neu erzeugen, damit das Index-Mapping korrekt bleibt.

## ğŸ§© Hinweise zur UI (aktuelle WahlmÃ¶glichkeiten)

- Es gibt keine Auswahl mehr zwischen â€String-Ã„hnlichkeitâ€œ und â€Embeddingsâ€œ. Die App nutzt ausschlieÃŸlich Embeddings.
- Der Button â€Embeddings vorrechnenâ€œ wurde entfernt; die App erwartet vorgefertigte Assets unter `public/quant/`.

## ğŸ¤ Contributing

1. Fork das Repository
2. Erstelle einen Feature Branch (`git checkout -b feature/amazing-feature`)
3. Committe deine Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. Push zum Branch (`git push origin feature/amazing-feature`)
5. Ã–ffne einen Pull Request

## ğŸ“„ Lizenz

Dieses Projekt steht unter der Apache 2.0 Lizenz - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.

## ğŸ™ Danksagungen

- [WirLernenOnline.de](https://wirlernenonline.de) fÃ¼r die Lernmaterialien-API
- [OpenAI](https://openai.com) fÃ¼r die LLM-API
- [GWDG](https://gwdg.de) fÃ¼r die alternative LLM-API
- React, Vite und alle verwendeten Open Source Libraries
